{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa98cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:13:09.893090: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 17:13:11.184220: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()        \n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "\n",
    "from preprocess.GraphTransformerPrerocess import graph_water_transformer_cov_process_for_gate_predictor\n",
    "from preprocess.graph import graph_topology, graph_topology_5\n",
    "from preprocess.BaselinePrerocess import gcn_process_for_gate_predictor\n",
    "from baselines.gcn import gcn_gate_generator_1\n",
    "\n",
    "from models.graph_water_transformer_cov import graph_water_transformer_cov_gate_predictor\n",
    "\n",
    "from losses.loss import gate_loss, water_level_threshold\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from postprocess.threshold import flood_threshold, drought_threshold, flood_threshold_t1, drought_threshold_t1\n",
    "from spektral.layers import GCNConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0092be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b8077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours = 72\n",
    "K = 24 \n",
    "masked_value = 1e-10\n",
    "split_1 = 0.8\n",
    "split_2 = 0.9\n",
    "sigma2 = 0.1\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8184307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WS_S1', 'WS_S4', 'FLOW_S25A', 'GATE_S25A', 'HWS_S25A', 'TWS_S25A',\n",
      "       'FLOW_S25B', 'GATE_S25B', 'GATE_S25B2', 'HWS_S25B', 'TWS_S25B',\n",
      "       'PUMP_S25B', 'FLOW_S26', 'GATE_S26_1', 'GATE_S26_2', 'HWS_S26',\n",
      "       'TWS_S26', 'PUMP_S26', 'MEAN_RAIN'],\n",
      "      dtype='object')\n",
      "train_X_mask.shape, val_X_mask.shape, test_X_mask.shape, train_ws_y.shape, val_ws_y.shape, test_ws_y.shape, train_gate_y.shape, val_gate_y.shape, test_gate_y.shape: (77069, 14, 96) (9634, 14, 96) (19268, 14, 96) (77069, 96) (9634, 96) (19268, 96) (77069, 24, 5) (9634, 24, 5) (19268, 24, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X_mask, val_X_mask, test_X_mask, \\\n",
    "train_ws_y, val_ws_y, test_ws_y, \\\n",
    "train_gate_y, val_gate_y, test_gate_y, \\\n",
    "scaler, ws_scaler, gate_scaler = gcn_process_for_gate_predictor(n_hours, K, masked_value, split_1, split_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a99f5ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WS_S1', 'WS_S4', 'FLOW_S25A', 'GATE_S25A', 'HWS_S25A', 'TWS_S25A',\n",
      "       'FLOW_S25B', 'GATE_S25B', 'GATE_S25B2', 'HWS_S25B', 'TWS_S25B',\n",
      "       'PUMP_S25B', 'FLOW_S26', 'GATE_S26_1', 'GATE_S26_2', 'HWS_S26',\n",
      "       'TWS_S26', 'PUMP_S26', 'MEAN_RAIN'],\n",
      "      dtype='object')\n",
      "train_tws/val_tws/test_tws: (77069, 5, 72) (9634, 5, 72) (19268, 5, 72) \n",
      " train_cov/val_cov/test_cov: (77069, 96, 12) (9634, 96, 12) (19268, 96, 12) \n",
      " train_ws_y/val_ws_y/test_ws_y: (77069, 96) (9634, 96) (19268, 96) \n",
      "  train_gate_pump_y/val_gate_pump_y/test_gate_pump_y: (77069, 24, 7) (9634, 24, 7) (19268, 24, 7)\n"
     ]
    }
   ],
   "source": [
    "train_cov, val_cov, test_cov, \\\n",
    "train_tws_reshape, val_tws_reshape, test_tws_reshape, \\\n",
    "train_gate_pump_y, val_gate_pump_y, test_gate_pump_y, \\\n",
    "train_ws_y, val_ws_y, test_ws_y, \\\n",
    "scaler, ws_scaler, gate_scalar = graph_water_transformer_cov_process_for_gate_predictor(n_hours, K, masked_value, split_1, split_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ed7ff",
   "metadata": {},
   "source": [
    "### Graph topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98e803d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_indices: [ 0  0  0  0  0  1  1  1  2  2  2  3  3  4  4  4  4  5  5  5  6  6  6  7\n",
      "  7  7  8  8  8  8  8  9  9  9 10 10 10 11 11 11 12 12 12 12 13 13 13 13\n",
      " 13 13 13 13 13 13 13 13 13 13] \n",
      "neighbor_indices: [ 1  4  8 12 13  1  4 13  3  4 13  2 13  0  1  2 13  7  8 13  7  8 13  5\n",
      "  6 13  0  5  6 12 13 11 12 13 11 12 13  9 10 13  0  9 10 13  0  1  2  3\n",
      "  4  5  6  7  8  9 10 11 12 13]\n",
      "number of nodes: 14, number of edges: 58\n"
     ]
    }
   ],
   "source": [
    "train_adj_mat_gcn, val_adj_mat_gcn, test_adj_mat_gcn = graph_topology(n_hours, K, sigma2, epsilon, len(train_ws_y), len(val_ws_y), len(test_ws_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8382e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_indices: [0 0 0 0 1 1 2 2 3 3 4 4] \n",
      "neighbor_indices: [1 2 3 4 0 2 0 1 0 4 0 3]\n",
      "number of nodes: 5, number of edges: 12\n"
     ]
    }
   ],
   "source": [
    "train_adj_mat, val_adj_mat, test_adj_mat = graph_topology_5(n_hours, K, sigma2, epsilon, len(train_ws_y), len(val_ws_y), len(test_ws_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003a2dc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861afcd",
   "metadata": {},
   "source": [
    "#### Gate & pump predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "685c4ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = train_adj_mat_gcn.shape[-1]\n",
    "n_timesteps = train_X_mask.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32cb80e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "gcn_unit1 = 32\n",
    "gcn_unit2 = 16\n",
    "lstm_units = 64\n",
    "dropout = 0\n",
    "gate_min = 0\n",
    "gate_max = 1\n",
    "\n",
    "\n",
    "learning_rate = 5e-4\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.9\n",
    "PATIENCE = 100\n",
    "EPOCHS = 700\n",
    "BATCH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79b6b40d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:13:28.254292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10402 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:88:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# n_nodes, n_timesteps, gcn1, gcn2, lstm_unit\n",
    "gate_predictor, GCNConv = gcn_gate_generator_1(gcn1=gcn_unit1,\n",
    "                                               gcn2=gcn_unit2,\n",
    "                                               n_nodes=n_nodes,\n",
    "                                               n_timesteps=n_timesteps,\n",
    "                                               lstm_unit=lstm_units,\n",
    "                                               dropout=dropout,\n",
    "                                               masked_value=masked_value,\n",
    "                                               gate_min=gate_min,\n",
    "                                               gate_max=gate_max\n",
    "                                              )\n",
    "gate_predictor._name = \"gate_predictor\"\n",
    "# gate_predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7023c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_predictor.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab7c93",
   "metadata": {},
   "source": [
    "#### water stage predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8002ff9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "ws_predictor = load_model('../saved_models/WaLeF_gtn_p.h5', custom_objects={'GCNConv': GCNConv})\n",
    "\n",
    "for layer in ws_predictor.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "ws_predictor._name = 'ws_predictor'    \n",
    "# ws_predictor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bce1a",
   "metadata": {},
   "source": [
    "#### Combine gate_predictor and trained ws_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "850a59ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs_feat = Input(shape=(14, 96), name='inputs_feat') # 96, 16\n",
    "inputs_adj_gcn = Input(shape=(14, 14), name='inputs_adj_gcn')\n",
    "inputs_tws = Input(shape=(5, 72), name='input_tws')\n",
    "inputs_adj = Input(shape=(5, 5), name='input_adj')\n",
    "\n",
    "# ================ gate_predictor ================\n",
    "gate_predictor_output = gate_predictor([inputs_feat, inputs_adj_gcn])  # (24, 7)\n",
    "\n",
    "\n",
    "# ============  future inputs with replaced gate & pump prediction ============\n",
    "inputs_ae_reshape = layers.Reshape((96, 14))(inputs_feat)\n",
    "replaced_future_gate_pump = layers.Concatenate(axis=-1)([inputs_ae_reshape[:, n_hours:, :2], \n",
    "                                                         gate_predictor_output, \n",
    "                                                         inputs_ae_reshape[:, n_hours:, 9:]\n",
    "                                                        ]\n",
    "                                                       )\n",
    "\n",
    "# ============ original past inputs + future inputs with replaced gate & pump prediction ============\n",
    "merged_inputs = layers.Concatenate(axis=1)([inputs_ae_reshape[:, :n_hours, :], replaced_future_gate_pump])  # (96, 16)\n",
    "merged_inputs_cov = merged_inputs[:, :, :12]\n",
    "\n",
    "ws_predictor_output = ws_predictor([merged_inputs_cov, inputs_tws, inputs_adj])\n",
    "\n",
    "filda = Model(inputs=[inputs_feat, inputs_adj_gcn, inputs_tws, inputs_adj], outputs=[gate_predictor_output, ws_predictor_output], name='filda')\n",
    "# filda.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf907f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "\n",
      "Epoch 1: val_ws_predictor_loss improved from inf to 2.82125, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 17s - loss: 0.7819 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2606 - val_loss: 8.4637 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 2.8212 - 17s/epoch - 114ms/step\n",
      "Epoch 2/700\n",
      "\n",
      "Epoch 2: val_ws_predictor_loss improved from 2.82125 to 2.41291, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.7368 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2456 - val_loss: 7.2387 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 2.4129 - 9s/epoch - 57ms/step\n",
      "Epoch 3/700\n",
      "\n",
      "Epoch 3: val_ws_predictor_loss improved from 2.41291 to 2.23439, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2285 - val_loss: 6.7032 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 2.2344 - 9s/epoch - 57ms/step\n",
      "Epoch 4/700\n",
      "\n",
      "Epoch 4: val_ws_predictor_loss improved from 2.23439 to 2.18781, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6610 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2203 - val_loss: 6.5634 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 2.1878 - 9s/epoch - 57ms/step\n",
      "Epoch 5/700\n",
      "\n",
      "Epoch 5: val_ws_predictor_loss improved from 2.18781 to 1.98310, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.6482 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2161 - val_loss: 5.9493 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.9831 - 8s/epoch - 56ms/step\n",
      "Epoch 6/700\n",
      "\n",
      "Epoch 6: val_ws_predictor_loss improved from 1.98310 to 1.83868, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.6329 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2110 - val_loss: 5.5160 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.8387 - 8s/epoch - 56ms/step\n",
      "Epoch 7/700\n",
      "\n",
      "Epoch 7: val_ws_predictor_loss improved from 1.83868 to 1.71007, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6246 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2082 - val_loss: 5.1302 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7101 - 9s/epoch - 57ms/step\n",
      "Epoch 8/700\n",
      "\n",
      "Epoch 8: val_ws_predictor_loss improved from 1.71007 to 1.65967, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.6170 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2057 - val_loss: 4.9790 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6597 - 8s/epoch - 56ms/step\n",
      "Epoch 9/700\n",
      "\n",
      "Epoch 9: val_ws_predictor_loss improved from 1.65967 to 1.65152, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6125 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2042 - val_loss: 4.9546 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6515 - 9s/epoch - 56ms/step\n",
      "Epoch 10/700\n",
      "\n",
      "Epoch 10: val_ws_predictor_loss improved from 1.65152 to 1.64456, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6114 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2038 - val_loss: 4.9337 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6446 - 9s/epoch - 57ms/step\n",
      "Epoch 11/700\n",
      "\n",
      "Epoch 11: val_ws_predictor_loss improved from 1.64456 to 1.59735, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.6075 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2025 - val_loss: 4.7920 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5973 - 8s/epoch - 56ms/step\n",
      "Epoch 12/700\n",
      "\n",
      "Epoch 12: val_ws_predictor_loss improved from 1.59735 to 1.58511, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6022 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2007 - val_loss: 4.7553 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5851 - 9s/epoch - 56ms/step\n",
      "Epoch 13/700\n",
      "\n",
      "Epoch 13: val_ws_predictor_loss improved from 1.58511 to 1.57813, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.6008 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2003 - val_loss: 4.7344 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5781 - 9s/epoch - 57ms/step\n",
      "Epoch 14/700\n",
      "\n",
      "Epoch 14: val_ws_predictor_loss did not improve from 1.57813\n",
      "151/151 - 8s - loss: 0.5991 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1997 - val_loss: 4.7358 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5786 - 8s/epoch - 56ms/step\n",
      "Epoch 15/700\n",
      "\n",
      "Epoch 15: val_ws_predictor_loss improved from 1.57813 to 1.57125, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5978 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1993 - val_loss: 4.7137 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5712 - 9s/epoch - 56ms/step\n",
      "Epoch 16/700\n",
      "\n",
      "Epoch 16: val_ws_predictor_loss did not improve from 1.57125\n",
      "151/151 - 8s - loss: 0.5973 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1991 - val_loss: 4.7271 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5757 - 8s/epoch - 56ms/step\n",
      "Epoch 17/700\n",
      "\n",
      "Epoch 17: val_ws_predictor_loss did not improve from 1.57125\n",
      "151/151 - 8s - loss: 0.5966 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1989 - val_loss: 4.7234 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5745 - 8s/epoch - 56ms/step\n",
      "Epoch 18/700\n",
      "\n",
      "Epoch 18: val_ws_predictor_loss improved from 1.57125 to 1.56977, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5963 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1988 - val_loss: 4.7093 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5698 - 8s/epoch - 56ms/step\n",
      "Epoch 19/700\n",
      "\n",
      "Epoch 19: val_ws_predictor_loss did not improve from 1.56977\n",
      "151/151 - 9s - loss: 0.5959 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1986 - val_loss: 4.7102 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5701 - 9s/epoch - 56ms/step\n",
      "Epoch 20/700\n",
      "\n",
      "Epoch 20: val_ws_predictor_loss improved from 1.56977 to 1.56033, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5955 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1985 - val_loss: 4.6810 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5603 - 8s/epoch - 56ms/step\n",
      "Epoch 21/700\n",
      "\n",
      "Epoch 21: val_ws_predictor_loss did not improve from 1.56033\n",
      "151/151 - 9s - loss: 0.5954 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1985 - val_loss: 4.7003 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5668 - 9s/epoch - 56ms/step\n",
      "Epoch 22/700\n",
      "\n",
      "Epoch 22: val_ws_predictor_loss did not improve from 1.56033\n",
      "151/151 - 9s - loss: 0.5949 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1983 - val_loss: 4.6871 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5624 - 9s/epoch - 57ms/step\n",
      "Epoch 23/700\n",
      "\n",
      "Epoch 23: val_ws_predictor_loss improved from 1.56033 to 1.55705, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5950 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1983 - val_loss: 4.6711 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5570 - 9s/epoch - 57ms/step\n",
      "Epoch 24/700\n",
      "\n",
      "Epoch 24: val_ws_predictor_loss did not improve from 1.55705\n",
      "151/151 - 8s - loss: 0.5947 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1982 - val_loss: 4.6717 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5572 - 8s/epoch - 56ms/step\n",
      "Epoch 25/700\n",
      "\n",
      "Epoch 25: val_ws_predictor_loss did not improve from 1.55705\n",
      "151/151 - 8s - loss: 0.5943 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1981 - val_loss: 4.6827 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5609 - 8s/epoch - 56ms/step\n",
      "Epoch 26/700\n",
      "\n",
      "Epoch 26: val_ws_predictor_loss improved from 1.55705 to 1.54986, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5943 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1981 - val_loss: 4.6496 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5499 - 8s/epoch - 56ms/step\n",
      "Epoch 27/700\n",
      "\n",
      "Epoch 27: val_ws_predictor_loss did not improve from 1.54986\n",
      "151/151 - 8s - loss: 0.5928 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1976 - val_loss: 4.6538 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5513 - 8s/epoch - 56ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/700\n",
      "\n",
      "Epoch 28: val_ws_predictor_loss improved from 1.54986 to 1.54830, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5908 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1969 - val_loss: 4.6449 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5483 - 9s/epoch - 57ms/step\n",
      "Epoch 29/700\n",
      "\n",
      "Epoch 29: val_ws_predictor_loss improved from 1.54830 to 1.54031, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5908 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1969 - val_loss: 4.6209 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5403 - 9s/epoch - 57ms/step\n",
      "Epoch 30/700\n",
      "\n",
      "Epoch 30: val_ws_predictor_loss improved from 1.54031 to 1.53971, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5906 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1969 - val_loss: 4.6191 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5397 - 9s/epoch - 57ms/step\n",
      "Epoch 31/700\n",
      "\n",
      "Epoch 31: val_ws_predictor_loss improved from 1.53971 to 1.53621, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5905 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1968 - val_loss: 4.6086 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5362 - 9s/epoch - 57ms/step\n",
      "Epoch 32/700\n",
      "\n",
      "Epoch 32: val_ws_predictor_loss improved from 1.53621 to 1.53166, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5904 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1968 - val_loss: 4.5950 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5317 - 9s/epoch - 57ms/step\n",
      "Epoch 33/700\n",
      "\n",
      "Epoch 33: val_ws_predictor_loss did not improve from 1.53166\n",
      "151/151 - 8s - loss: 0.5901 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1967 - val_loss: 4.6194 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5398 - 8s/epoch - 56ms/step\n",
      "Epoch 34/700\n",
      "\n",
      "Epoch 34: val_ws_predictor_loss did not improve from 1.53166\n",
      "151/151 - 9s - loss: 0.5901 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1967 - val_loss: 4.6038 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5346 - 9s/epoch - 56ms/step\n",
      "Epoch 35/700\n",
      "\n",
      "Epoch 35: val_ws_predictor_loss improved from 1.53166 to 1.53163, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5903 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1968 - val_loss: 4.5949 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5316 - 9s/epoch - 57ms/step\n",
      "Epoch 36/700\n",
      "\n",
      "Epoch 36: val_ws_predictor_loss improved from 1.53163 to 1.52735, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5899 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1966 - val_loss: 4.5821 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5273 - 9s/epoch - 57ms/step\n",
      "Epoch 37/700\n",
      "\n",
      "Epoch 37: val_ws_predictor_loss improved from 1.52735 to 1.52558, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5897 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1966 - val_loss: 4.5768 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5256 - 9s/epoch - 57ms/step\n",
      "Epoch 38/700\n",
      "\n",
      "Epoch 38: val_ws_predictor_loss did not improve from 1.52558\n",
      "151/151 - 8s - loss: 0.5895 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1965 - val_loss: 4.5881 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5294 - 8s/epoch - 56ms/step\n",
      "Epoch 39/700\n",
      "\n",
      "Epoch 39: val_ws_predictor_loss improved from 1.52558 to 1.52403, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5895 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1965 - val_loss: 4.5721 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5240 - 9s/epoch - 56ms/step\n",
      "Epoch 40/700\n",
      "\n",
      "Epoch 40: val_ws_predictor_loss did not improve from 1.52403\n",
      "151/151 - 8s - loss: 0.5894 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1965 - val_loss: 4.5725 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5242 - 8s/epoch - 56ms/step\n",
      "Epoch 41/700\n",
      "\n",
      "Epoch 41: val_ws_predictor_loss improved from 1.52403 to 1.51798, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5893 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1964 - val_loss: 4.5539 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5180 - 9s/epoch - 57ms/step\n",
      "Epoch 42/700\n",
      "\n",
      "Epoch 42: val_ws_predictor_loss did not improve from 1.51798\n",
      "151/151 - 8s - loss: 0.5892 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1964 - val_loss: 4.5553 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5184 - 8s/epoch - 56ms/step\n",
      "Epoch 43/700\n",
      "\n",
      "Epoch 43: val_ws_predictor_loss improved from 1.51798 to 1.51493, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5890 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1963 - val_loss: 4.5448 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5149 - 8s/epoch - 56ms/step\n",
      "Epoch 44/700\n",
      "\n",
      "Epoch 44: val_ws_predictor_loss did not improve from 1.51493\n",
      "151/151 - 8s - loss: 0.5891 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1964 - val_loss: 4.5526 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5175 - 8s/epoch - 56ms/step\n",
      "Epoch 45/700\n",
      "\n",
      "Epoch 45: val_ws_predictor_loss improved from 1.51493 to 1.51159, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5891 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1964 - val_loss: 4.5348 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5116 - 9s/epoch - 57ms/step\n",
      "Epoch 46/700\n",
      "\n",
      "Epoch 46: val_ws_predictor_loss improved from 1.51159 to 1.51048, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5888 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1963 - val_loss: 4.5315 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5105 - 9s/epoch - 57ms/step\n",
      "Epoch 47/700\n",
      "\n",
      "Epoch 47: val_ws_predictor_loss did not improve from 1.51048\n",
      "151/151 - 8s - loss: 0.5887 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1962 - val_loss: 4.5407 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5136 - 8s/epoch - 56ms/step\n",
      "Epoch 48/700\n",
      "\n",
      "Epoch 48: val_ws_predictor_loss improved from 1.51048 to 1.50749, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5887 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1962 - val_loss: 4.5225 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5075 - 9s/epoch - 56ms/step\n",
      "Epoch 49/700\n",
      "\n",
      "Epoch 49: val_ws_predictor_loss improved from 1.50749 to 1.50629, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5886 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1962 - val_loss: 4.5189 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5063 - 9s/epoch - 58ms/step\n",
      "Epoch 50/700\n",
      "\n",
      "Epoch 50: val_ws_predictor_loss improved from 1.50629 to 1.50595, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5886 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1962 - val_loss: 4.5179 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5060 - 9s/epoch - 58ms/step\n",
      "Epoch 51/700\n",
      "\n",
      "Epoch 51: val_ws_predictor_loss improved from 1.50595 to 1.50442, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5884 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.5133 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5044 - 9s/epoch - 56ms/step\n",
      "Epoch 52/700\n",
      "\n",
      "Epoch 52: val_ws_predictor_loss improved from 1.50442 to 1.50122, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5884 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.5037 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5012 - 9s/epoch - 57ms/step\n",
      "Epoch 53/700\n",
      "\n",
      "Epoch 53: val_ws_predictor_loss did not improve from 1.50122\n",
      "151/151 - 8s - loss: 0.5884 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.5191 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5064 - 8s/epoch - 56ms/step\n",
      "Epoch 54/700\n",
      "\n",
      "Epoch 54: val_ws_predictor_loss did not improve from 1.50122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 8s - loss: 0.5882 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.5165 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5055 - 8s/epoch - 56ms/step\n",
      "Epoch 55/700\n",
      "\n",
      "Epoch 55: val_ws_predictor_loss did not improve from 1.50122\n",
      "151/151 - 8s - loss: 0.5882 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.5207 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5069 - 8s/epoch - 56ms/step\n",
      "Epoch 56/700\n",
      "\n",
      "Epoch 56: val_ws_predictor_loss did not improve from 1.50122\n",
      "151/151 - 8s - loss: 0.5881 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.5148 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5049 - 8s/epoch - 56ms/step\n",
      "Epoch 57/700\n",
      "\n",
      "Epoch 57: val_ws_predictor_loss improved from 1.50122 to 1.49874, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5882 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1961 - val_loss: 4.4962 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4987 - 8s/epoch - 56ms/step\n",
      "Epoch 58/700\n",
      "\n",
      "Epoch 58: val_ws_predictor_loss did not improve from 1.49874\n",
      "151/151 - 8s - loss: 0.5880 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.5065 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5022 - 8s/epoch - 56ms/step\n",
      "Epoch 59/700\n",
      "\n",
      "Epoch 59: val_ws_predictor_loss did not improve from 1.49874\n",
      "151/151 - 8s - loss: 0.5880 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.5091 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5030 - 8s/epoch - 56ms/step\n",
      "Epoch 60/700\n",
      "\n",
      "Epoch 60: val_ws_predictor_loss improved from 1.49874 to 1.49756, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5879 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.4927 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4976 - 8s/epoch - 56ms/step\n",
      "Epoch 61/700\n",
      "\n",
      "Epoch 61: val_ws_predictor_loss did not improve from 1.49756\n",
      "151/151 - 8s - loss: 0.5879 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.5157 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5052 - 8s/epoch - 56ms/step\n",
      "Epoch 62/700\n",
      "\n",
      "Epoch 62: val_ws_predictor_loss improved from 1.49756 to 1.49694, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5879 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.4908 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4969 - 9s/epoch - 57ms/step\n",
      "Epoch 63/700\n",
      "\n",
      "Epoch 63: val_ws_predictor_loss improved from 1.49694 to 1.49424, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5879 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.4827 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4942 - 8s/epoch - 56ms/step\n",
      "Epoch 64/700\n",
      "\n",
      "Epoch 64: val_ws_predictor_loss did not improve from 1.49424\n",
      "151/151 - 8s - loss: 0.5877 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1959 - val_loss: 4.4963 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4988 - 8s/epoch - 56ms/step\n",
      "Epoch 65/700\n",
      "\n",
      "Epoch 65: val_ws_predictor_loss did not improve from 1.49424\n",
      "151/151 - 8s - loss: 0.5876 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1959 - val_loss: 4.4839 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4946 - 8s/epoch - 56ms/step\n",
      "Epoch 66/700\n",
      "\n",
      "Epoch 66: val_ws_predictor_loss did not improve from 1.49424\n",
      "151/151 - 8s - loss: 0.5881 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 4.4844 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4948 - 8s/epoch - 56ms/step\n",
      "Epoch 67/700\n",
      "\n",
      "Epoch 67: val_ws_predictor_loss did not improve from 1.49424\n",
      "151/151 - 8s - loss: 0.5877 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1959 - val_loss: 4.4973 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4991 - 8s/epoch - 56ms/step\n",
      "Epoch 68/700\n",
      "\n",
      "Epoch 68: val_ws_predictor_loss improved from 1.49424 to 1.49164, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5874 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4749 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4916 - 9s/epoch - 56ms/step\n",
      "Epoch 69/700\n",
      "\n",
      "Epoch 69: val_ws_predictor_loss did not improve from 1.49164\n",
      "151/151 - 8s - loss: 0.5876 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1959 - val_loss: 4.4836 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4945 - 8s/epoch - 56ms/step\n",
      "Epoch 70/700\n",
      "\n",
      "Epoch 70: val_ws_predictor_loss did not improve from 1.49164\n",
      "151/151 - 9s - loss: 0.5875 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4830 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4943 - 9s/epoch - 56ms/step\n",
      "Epoch 71/700\n",
      "\n",
      "Epoch 71: val_ws_predictor_loss did not improve from 1.49164\n",
      "151/151 - 8s - loss: 0.5876 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1959 - val_loss: 4.4886 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4962 - 8s/epoch - 56ms/step\n",
      "Epoch 72/700\n",
      "\n",
      "Epoch 72: val_ws_predictor_loss improved from 1.49164 to 1.49134, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5874 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4740 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4913 - 9s/epoch - 57ms/step\n",
      "Epoch 73/700\n",
      "\n",
      "Epoch 73: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 9s - loss: 0.5873 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4748 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4916 - 9s/epoch - 57ms/step\n",
      "Epoch 74/700\n",
      "\n",
      "Epoch 74: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 8s - loss: 0.5873 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4807 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4936 - 8s/epoch - 56ms/step\n",
      "Epoch 75/700\n",
      "\n",
      "Epoch 75: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 8s - loss: 0.5874 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 4.4807 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4936 - 8s/epoch - 56ms/step\n",
      "Epoch 76/700\n",
      "\n",
      "Epoch 76: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 8s - loss: 0.5872 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4747 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4916 - 8s/epoch - 56ms/step\n",
      "Epoch 77/700\n",
      "\n",
      "Epoch 77: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 8s - loss: 0.5872 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4937 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4979 - 8s/epoch - 56ms/step\n",
      "Epoch 78/700\n",
      "\n",
      "Epoch 78: val_ws_predictor_loss did not improve from 1.49134\n",
      "151/151 - 8s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4755 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4918 - 8s/epoch - 56ms/step\n",
      "Epoch 79/700\n",
      "\n",
      "Epoch 79: val_ws_predictor_loss improved from 1.49134 to 1.49132, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4740 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4913 - 9s/epoch - 57ms/step\n",
      "Epoch 80/700\n",
      "\n",
      "Epoch 80: val_ws_predictor_loss improved from 1.49132 to 1.49001, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4700 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4900 - 9s/epoch - 57ms/step\n",
      "Epoch 81/700\n",
      "\n",
      "Epoch 81: val_ws_predictor_loss did not improve from 1.49001\n",
      "151/151 - 9s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4708 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4903 - 9s/epoch - 56ms/step\n",
      "Epoch 82/700\n",
      "\n",
      "Epoch 82: val_ws_predictor_loss improved from 1.49001 to 1.48860, saving model to ../saved_models/gcn_gtnp_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 9s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4658 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4886 - 9s/epoch - 56ms/step\n",
      "Epoch 83/700\n",
      "\n",
      "Epoch 83: val_ws_predictor_loss did not improve from 1.48860\n",
      "151/151 - 8s - loss: 0.5871 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4697 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4899 - 8s/epoch - 56ms/step\n",
      "Epoch 84/700\n",
      "\n",
      "Epoch 84: val_ws_predictor_loss improved from 1.48860 to 1.48848, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5870 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4654 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4885 - 9s/epoch - 57ms/step\n",
      "Epoch 85/700\n",
      "\n",
      "Epoch 85: val_ws_predictor_loss improved from 1.48848 to 1.48616, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5870 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4585 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4862 - 9s/epoch - 57ms/step\n",
      "Epoch 86/700\n",
      "\n",
      "Epoch 86: val_ws_predictor_loss did not improve from 1.48616\n",
      "151/151 - 8s - loss: 0.5869 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4611 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4870 - 8s/epoch - 56ms/step\n",
      "Epoch 87/700\n",
      "\n",
      "Epoch 87: val_ws_predictor_loss did not improve from 1.48616\n",
      "151/151 - 8s - loss: 0.5870 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1957 - val_loss: 4.4703 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4901 - 8s/epoch - 56ms/step\n",
      "Epoch 88/700\n",
      "\n",
      "Epoch 88: val_ws_predictor_loss did not improve from 1.48616\n",
      "151/151 - 8s - loss: 0.5869 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4688 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4896 - 8s/epoch - 56ms/step\n",
      "Epoch 89/700\n",
      "\n",
      "Epoch 89: val_ws_predictor_loss improved from 1.48616 to 1.48578, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5869 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4573 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4858 - 9s/epoch - 57ms/step\n",
      "Epoch 90/700\n",
      "\n",
      "Epoch 90: val_ws_predictor_loss improved from 1.48578 to 1.48482, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5868 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4545 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4848 - 9s/epoch - 57ms/step\n",
      "Epoch 91/700\n",
      "\n",
      "Epoch 91: val_ws_predictor_loss did not improve from 1.48482\n",
      "151/151 - 9s - loss: 0.5868 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4684 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4895 - 9s/epoch - 57ms/step\n",
      "Epoch 92/700\n",
      "\n",
      "Epoch 92: val_ws_predictor_loss improved from 1.48482 to 1.48405, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5869 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4521 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4840 - 9s/epoch - 56ms/step\n",
      "Epoch 93/700\n",
      "\n",
      "Epoch 93: val_ws_predictor_loss did not improve from 1.48405\n",
      "151/151 - 8s - loss: 0.5867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4531 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4844 - 8s/epoch - 56ms/step\n",
      "Epoch 94/700\n",
      "\n",
      "Epoch 94: val_ws_predictor_loss improved from 1.48405 to 1.48275, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5869 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4482 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4827 - 9s/epoch - 57ms/step\n",
      "Epoch 95/700\n",
      "\n",
      "Epoch 95: val_ws_predictor_loss did not improve from 1.48275\n",
      "151/151 - 8s - loss: 0.5867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4549 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4850 - 8s/epoch - 56ms/step\n",
      "Epoch 96/700\n",
      "\n",
      "Epoch 96: val_ws_predictor_loss did not improve from 1.48275\n",
      "151/151 - 8s - loss: 0.5866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4527 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4842 - 8s/epoch - 56ms/step\n",
      "Epoch 97/700\n",
      "\n",
      "Epoch 97: val_ws_predictor_loss did not improve from 1.48275\n",
      "151/151 - 8s - loss: 0.5867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4599 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4866 - 8s/epoch - 56ms/step\n",
      "Epoch 98/700\n",
      "\n",
      "Epoch 98: val_ws_predictor_loss did not improve from 1.48275\n",
      "151/151 - 8s - loss: 0.5867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4517 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4839 - 8s/epoch - 56ms/step\n",
      "Epoch 99/700\n",
      "\n",
      "Epoch 99: val_ws_predictor_loss improved from 1.48275 to 1.48189, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4457 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4819 - 9s/epoch - 57ms/step\n",
      "Epoch 100/700\n",
      "\n",
      "Epoch 100: val_ws_predictor_loss improved from 1.48189 to 1.47940, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4382 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4794 - 8s/epoch - 56ms/step\n",
      "Epoch 101/700\n",
      "\n",
      "Epoch 101: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4425 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4808 - 8s/epoch - 56ms/step\n",
      "Epoch 102/700\n",
      "\n",
      "Epoch 102: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1956 - val_loss: 4.4485 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4828 - 8s/epoch - 56ms/step\n",
      "Epoch 103/700\n",
      "\n",
      "Epoch 103: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5865 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4426 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4809 - 8s/epoch - 56ms/step\n",
      "Epoch 104/700\n",
      "\n",
      "Epoch 104: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 9s - loss: 0.5866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4413 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4804 - 9s/epoch - 56ms/step\n",
      "Epoch 105/700\n",
      "\n",
      "Epoch 105: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5865 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4398 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4799 - 8s/epoch - 56ms/step\n",
      "Epoch 106/700\n",
      "\n",
      "Epoch 106: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4487 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4829 - 8s/epoch - 56ms/step\n",
      "Epoch 107/700\n",
      "\n",
      "Epoch 107: val_ws_predictor_loss did not improve from 1.47940\n",
      "151/151 - 8s - loss: 0.5865 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4508 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4836 - 8s/epoch - 56ms/step\n",
      "Epoch 108/700\n",
      "\n",
      "Epoch 108: val_ws_predictor_loss improved from 1.47940 to 1.47918, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4375 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4792 - 8s/epoch - 56ms/step\n",
      "Epoch 109/700\n",
      "\n",
      "Epoch 109: val_ws_predictor_loss did not improve from 1.47918\n",
      "151/151 - 8s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4438 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4813 - 8s/epoch - 56ms/step\n",
      "Epoch 110/700\n",
      "\n",
      "Epoch 110: val_ws_predictor_loss did not improve from 1.47918\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 8s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4399 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4800 - 8s/epoch - 56ms/step\n",
      "Epoch 111/700\n",
      "\n",
      "Epoch 111: val_ws_predictor_loss improved from 1.47918 to 1.47737, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4321 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4774 - 9s/epoch - 56ms/step\n",
      "Epoch 112/700\n",
      "\n",
      "Epoch 112: val_ws_predictor_loss did not improve from 1.47737\n",
      "151/151 - 8s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4406 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4802 - 8s/epoch - 56ms/step\n",
      "Epoch 113/700\n",
      "\n",
      "Epoch 113: val_ws_predictor_loss did not improve from 1.47737\n",
      "151/151 - 8s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4394 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4798 - 8s/epoch - 56ms/step\n",
      "Epoch 114/700\n",
      "\n",
      "Epoch 114: val_ws_predictor_loss did not improve from 1.47737\n",
      "151/151 - 9s - loss: 0.5864 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1955 - val_loss: 4.4408 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4803 - 9s/epoch - 58ms/step\n",
      "Epoch 115/700\n",
      "\n",
      "Epoch 115: val_ws_predictor_loss did not improve from 1.47737\n",
      "151/151 - 8s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4394 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4798 - 8s/epoch - 56ms/step\n",
      "Epoch 116/700\n",
      "\n",
      "Epoch 116: val_ws_predictor_loss improved from 1.47737 to 1.47640, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4292 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4764 - 9s/epoch - 57ms/step\n",
      "Epoch 117/700\n",
      "\n",
      "Epoch 117: val_ws_predictor_loss improved from 1.47640 to 1.47543, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4263 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4754 - 8s/epoch - 56ms/step\n",
      "Epoch 118/700\n",
      "\n",
      "Epoch 118: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 9s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4298 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4766 - 9s/epoch - 56ms/step\n",
      "Epoch 119/700\n",
      "\n",
      "Epoch 119: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 9s - loss: 0.5862 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4302 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4767 - 9s/epoch - 57ms/step\n",
      "Epoch 120/700\n",
      "\n",
      "Epoch 120: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 8s - loss: 0.5862 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4410 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4803 - 8s/epoch - 56ms/step\n",
      "Epoch 121/700\n",
      "\n",
      "Epoch 121: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 8s - loss: 0.5862 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4319 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4773 - 8s/epoch - 56ms/step\n",
      "Epoch 122/700\n",
      "\n",
      "Epoch 122: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 9s - loss: 0.5863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4333 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4778 - 9s/epoch - 57ms/step\n",
      "Epoch 123/700\n",
      "\n",
      "Epoch 123: val_ws_predictor_loss did not improve from 1.47543\n",
      "151/151 - 8s - loss: 0.5862 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1954 - val_loss: 4.4335 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4778 - 8s/epoch - 56ms/step\n",
      "Epoch 124/700\n",
      "\n",
      "Epoch 124: val_ws_predictor_loss improved from 1.47543 to 1.46466, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5859 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.3940 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4647 - 8s/epoch - 56ms/step\n",
      "Epoch 125/700\n",
      "\n",
      "Epoch 125: val_ws_predictor_loss did not improve from 1.46466\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.4096 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4699 - 8s/epoch - 56ms/step\n",
      "Epoch 126/700\n",
      "\n",
      "Epoch 126: val_ws_predictor_loss did not improve from 1.46466\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.4018 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4673 - 8s/epoch - 56ms/step\n",
      "Epoch 127/700\n",
      "\n",
      "Epoch 127: val_ws_predictor_loss did not improve from 1.46466\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.4012 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4671 - 8s/epoch - 56ms/step\n",
      "Epoch 128/700\n",
      "\n",
      "Epoch 128: val_ws_predictor_loss did not improve from 1.46466\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.4110 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4703 - 8s/epoch - 56ms/step\n",
      "Epoch 129/700\n",
      "\n",
      "Epoch 129: val_ws_predictor_loss did not improve from 1.46466\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.4031 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4677 - 8s/epoch - 56ms/step\n",
      "Epoch 130/700\n",
      "\n",
      "Epoch 130: val_ws_predictor_loss improved from 1.46466 to 1.46418, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3925 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4642 - 9s/epoch - 57ms/step\n",
      "Epoch 131/700\n",
      "\n",
      "Epoch 131: val_ws_predictor_loss did not improve from 1.46418\n",
      "151/151 - 8s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.4059 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4686 - 8s/epoch - 56ms/step\n",
      "Epoch 132/700\n",
      "\n",
      "Epoch 132: val_ws_predictor_loss did not improve from 1.46418\n",
      "151/151 - 8s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.3961 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4654 - 8s/epoch - 56ms/step\n",
      "Epoch 133/700\n",
      "\n",
      "Epoch 133: val_ws_predictor_loss did not improve from 1.46418\n",
      "151/151 - 8s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3957 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4652 - 8s/epoch - 55ms/step\n",
      "Epoch 134/700\n",
      "\n",
      "Epoch 134: val_ws_predictor_loss improved from 1.46418 to 1.46388, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3916 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4639 - 9s/epoch - 56ms/step\n",
      "Epoch 135/700\n",
      "\n",
      "Epoch 135: val_ws_predictor_loss improved from 1.46388 to 1.46135, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5858 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 4.3840 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4613 - 9s/epoch - 56ms/step\n",
      "Epoch 136/700\n",
      "\n",
      "Epoch 136: val_ws_predictor_loss did not improve from 1.46135\n",
      "151/151 - 8s - loss: 0.5856 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3992 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4664 - 8s/epoch - 56ms/step\n",
      "Epoch 137/700\n",
      "\n",
      "Epoch 137: val_ws_predictor_loss did not improve from 1.46135\n",
      "151/151 - 8s - loss: 0.5856 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3899 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4633 - 8s/epoch - 56ms/step\n",
      "Epoch 138/700\n",
      "\n",
      "Epoch 138: val_ws_predictor_loss improved from 1.46135 to 1.46084, saving model to ../saved_models/gcn_gtnp_1.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 9s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3825 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4608 - 9s/epoch - 56ms/step\n",
      "Epoch 139/700\n",
      "\n",
      "Epoch 139: val_ws_predictor_loss did not improve from 1.46084\n",
      "151/151 - 9s - loss: 0.5856 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3886 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4629 - 9s/epoch - 56ms/step\n",
      "Epoch 140/700\n",
      "\n",
      "Epoch 140: val_ws_predictor_loss did not improve from 1.46084\n",
      "151/151 - 8s - loss: 0.5856 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3845 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4615 - 8s/epoch - 56ms/step\n",
      "Epoch 141/700\n",
      "\n",
      "Epoch 141: val_ws_predictor_loss improved from 1.46084 to 1.46047, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3814 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4605 - 8s/epoch - 56ms/step\n",
      "Epoch 142/700\n",
      "\n",
      "Epoch 142: val_ws_predictor_loss improved from 1.46047 to 1.45850, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 8s - loss: 0.5856 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3755 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4585 - 8s/epoch - 56ms/step\n",
      "Epoch 143/700\n",
      "\n",
      "Epoch 143: val_ws_predictor_loss did not improve from 1.45850\n",
      "151/151 - 8s - loss: 0.5857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3764 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4588 - 8s/epoch - 56ms/step\n",
      "Epoch 144/700\n",
      "\n",
      "Epoch 144: val_ws_predictor_loss did not improve from 1.45850\n",
      "151/151 - 8s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3808 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4603 - 8s/epoch - 56ms/step\n",
      "Epoch 145/700\n",
      "\n",
      "Epoch 145: val_ws_predictor_loss improved from 1.45850 to 1.45737, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3721 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4574 - 9s/epoch - 56ms/step\n",
      "Epoch 146/700\n",
      "\n",
      "Epoch 146: val_ws_predictor_loss did not improve from 1.45737\n",
      "151/151 - 8s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3798 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4599 - 8s/epoch - 56ms/step\n",
      "Epoch 147/700\n",
      "\n",
      "Epoch 147: val_ws_predictor_loss improved from 1.45737 to 1.45687, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3706 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4569 - 9s/epoch - 56ms/step\n",
      "Epoch 148/700\n",
      "\n",
      "Epoch 148: val_ws_predictor_loss did not improve from 1.45687\n",
      "151/151 - 8s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3730 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4577 - 8s/epoch - 56ms/step\n",
      "Epoch 149/700\n",
      "\n",
      "Epoch 149: val_ws_predictor_loss improved from 1.45687 to 1.45479, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3644 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4548 - 9s/epoch - 56ms/step\n",
      "Epoch 150/700\n",
      "\n",
      "Epoch 150: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3806 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4602 - 8s/epoch - 56ms/step\n",
      "Epoch 151/700\n",
      "\n",
      "Epoch 151: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5855 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1952 - val_loss: 4.3735 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4578 - 8s/epoch - 56ms/step\n",
      "Epoch 152/700\n",
      "\n",
      "Epoch 152: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3798 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4599 - 8s/epoch - 55ms/step\n",
      "Epoch 153/700\n",
      "\n",
      "Epoch 153: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3764 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4588 - 8s/epoch - 56ms/step\n",
      "Epoch 154/700\n",
      "\n",
      "Epoch 154: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3700 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4567 - 8s/epoch - 56ms/step\n",
      "Epoch 155/700\n",
      "\n",
      "Epoch 155: val_ws_predictor_loss did not improve from 1.45479\n",
      "151/151 - 8s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3676 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4559 - 8s/epoch - 56ms/step\n",
      "Epoch 156/700\n",
      "\n",
      "Epoch 156: val_ws_predictor_loss improved from 1.45479 to 1.45456, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3637 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4546 - 9s/epoch - 56ms/step\n",
      "Epoch 157/700\n",
      "\n",
      "Epoch 157: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3740 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4580 - 8s/epoch - 56ms/step\n",
      "Epoch 158/700\n",
      "\n",
      "Epoch 158: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3739 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4580 - 8s/epoch - 56ms/step\n",
      "Epoch 159/700\n",
      "\n",
      "Epoch 159: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 9s - loss: 0.5854 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3747 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4582 - 9s/epoch - 57ms/step\n",
      "Epoch 160/700\n",
      "\n",
      "Epoch 160: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 9s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3727 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4576 - 9s/epoch - 56ms/step\n",
      "Epoch 161/700\n",
      "\n",
      "Epoch 161: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3707 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4569 - 8s/epoch - 56ms/step\n",
      "Epoch 162/700\n",
      "\n",
      "Epoch 162: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3673 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4558 - 8s/epoch - 56ms/step\n",
      "Epoch 163/700\n",
      "\n",
      "Epoch 163: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3855 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4618 - 8s/epoch - 56ms/step\n",
      "Epoch 164/700\n",
      "\n",
      "Epoch 164: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3771 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4590 - 8s/epoch - 56ms/step\n",
      "Epoch 165/700\n",
      "\n",
      "Epoch 165: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3692 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4564 - 8s/epoch - 56ms/step\n",
      "Epoch 166/700\n",
      "\n",
      "Epoch 166: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3705 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4568 - 8s/epoch - 56ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/700\n",
      "\n",
      "Epoch 167: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3876 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4625 - 8s/epoch - 56ms/step\n",
      "Epoch 168/700\n",
      "\n",
      "Epoch 168: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3697 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4566 - 8s/epoch - 56ms/step\n",
      "Epoch 169/700\n",
      "\n",
      "Epoch 169: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3732 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4577 - 8s/epoch - 56ms/step\n",
      "Epoch 170/700\n",
      "\n",
      "Epoch 170: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3687 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4562 - 8s/epoch - 56ms/step\n",
      "Epoch 171/700\n",
      "\n",
      "Epoch 171: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3762 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4587 - 8s/epoch - 56ms/step\n",
      "Epoch 172/700\n",
      "\n",
      "Epoch 172: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3661 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4554 - 8s/epoch - 56ms/step\n",
      "Epoch 173/700\n",
      "\n",
      "Epoch 173: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5853 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3752 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4584 - 8s/epoch - 56ms/step\n",
      "Epoch 174/700\n",
      "\n",
      "Epoch 174: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3731 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4577 - 8s/epoch - 56ms/step\n",
      "Epoch 175/700\n",
      "\n",
      "Epoch 175: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3676 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4559 - 8s/epoch - 56ms/step\n",
      "Epoch 176/700\n",
      "\n",
      "Epoch 176: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3688 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4563 - 8s/epoch - 56ms/step\n",
      "Epoch 177/700\n",
      "\n",
      "Epoch 177: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1951 - val_loss: 4.3706 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4569 - 8s/epoch - 56ms/step\n",
      "Epoch 178/700\n",
      "\n",
      "Epoch 178: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3731 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4577 - 8s/epoch - 56ms/step\n",
      "Epoch 179/700\n",
      "\n",
      "Epoch 179: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3652 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4551 - 8s/epoch - 56ms/step\n",
      "Epoch 180/700\n",
      "\n",
      "Epoch 180: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3720 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4573 - 8s/epoch - 56ms/step\n",
      "Epoch 181/700\n",
      "\n",
      "Epoch 181: val_ws_predictor_loss did not improve from 1.45456\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3729 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4576 - 8s/epoch - 56ms/step\n",
      "Epoch 182/700\n",
      "\n",
      "Epoch 182: val_ws_predictor_loss improved from 1.45456 to 1.45315, saving model to ../saved_models/gcn_gtnp_1.h5\n",
      "151/151 - 9s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3595 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4532 - 9s/epoch - 56ms/step\n",
      "Epoch 183/700\n",
      "\n",
      "Epoch 183: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3766 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4589 - 8s/epoch - 56ms/step\n",
      "Epoch 184/700\n",
      "\n",
      "Epoch 184: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3676 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4559 - 8s/epoch - 56ms/step\n",
      "Epoch 185/700\n",
      "\n",
      "Epoch 185: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3700 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4567 - 8s/epoch - 56ms/step\n",
      "Epoch 186/700\n",
      "\n",
      "Epoch 186: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3725 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4575 - 9s/epoch - 56ms/step\n",
      "Epoch 187/700\n",
      "\n",
      "Epoch 187: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3784 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4595 - 8s/epoch - 56ms/step\n",
      "Epoch 188/700\n",
      "\n",
      "Epoch 188: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3664 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4555 - 8s/epoch - 56ms/step\n",
      "Epoch 189/700\n",
      "\n",
      "Epoch 189: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3794 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4598 - 9s/epoch - 56ms/step\n",
      "Epoch 190/700\n",
      "\n",
      "Epoch 190: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3690 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4563 - 9s/epoch - 56ms/step\n",
      "Epoch 191/700\n",
      "\n",
      "Epoch 191: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3694 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4565 - 8s/epoch - 56ms/step\n",
      "Epoch 192/700\n",
      "\n",
      "Epoch 192: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3853 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4618 - 8s/epoch - 56ms/step\n",
      "Epoch 193/700\n",
      "\n",
      "Epoch 193: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3615 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4538 - 8s/epoch - 56ms/step\n",
      "Epoch 194/700\n",
      "\n",
      "Epoch 194: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3724 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4575 - 8s/epoch - 56ms/step\n",
      "Epoch 195/700\n",
      "\n",
      "Epoch 195: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3803 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4601 - 8s/epoch - 56ms/step\n",
      "Epoch 196/700\n",
      "\n",
      "Epoch 196: val_ws_predictor_loss did not improve from 1.45315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3715 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4572 - 8s/epoch - 56ms/step\n",
      "Epoch 197/700\n",
      "\n",
      "Epoch 197: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3641 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4547 - 8s/epoch - 56ms/step\n",
      "Epoch 198/700\n",
      "\n",
      "Epoch 198: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3626 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4542 - 9s/epoch - 56ms/step\n",
      "Epoch 199/700\n",
      "\n",
      "Epoch 199: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3653 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4551 - 8s/epoch - 56ms/step\n",
      "Epoch 200/700\n",
      "\n",
      "Epoch 200: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3704 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4568 - 8s/epoch - 56ms/step\n",
      "Epoch 201/700\n",
      "\n",
      "Epoch 201: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3802 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4601 - 8s/epoch - 56ms/step\n",
      "Epoch 202/700\n",
      "\n",
      "Epoch 202: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3633 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4544 - 8s/epoch - 56ms/step\n",
      "Epoch 203/700\n",
      "\n",
      "Epoch 203: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3699 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4566 - 8s/epoch - 56ms/step\n",
      "Epoch 204/700\n",
      "\n",
      "Epoch 204: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3667 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4556 - 8s/epoch - 56ms/step\n",
      "Epoch 205/700\n",
      "\n",
      "Epoch 205: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3692 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4564 - 8s/epoch - 56ms/step\n",
      "Epoch 206/700\n",
      "\n",
      "Epoch 206: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5850 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3780 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4593 - 8s/epoch - 56ms/step\n",
      "Epoch 207/700\n",
      "\n",
      "Epoch 207: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3641 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4547 - 8s/epoch - 56ms/step\n",
      "Epoch 208/700\n",
      "\n",
      "Epoch 208: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3717 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4572 - 8s/epoch - 56ms/step\n",
      "Epoch 209/700\n",
      "\n",
      "Epoch 209: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3756 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4585 - 9s/epoch - 57ms/step\n",
      "Epoch 210/700\n",
      "\n",
      "Epoch 210: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3737 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4579 - 8s/epoch - 56ms/step\n",
      "Epoch 211/700\n",
      "\n",
      "Epoch 211: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3653 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4551 - 8s/epoch - 56ms/step\n",
      "Epoch 212/700\n",
      "\n",
      "Epoch 212: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3647 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4549 - 8s/epoch - 56ms/step\n",
      "Epoch 213/700\n",
      "\n",
      "Epoch 213: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3598 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4533 - 8s/epoch - 56ms/step\n",
      "Epoch 214/700\n",
      "\n",
      "Epoch 214: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3669 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4556 - 8s/epoch - 56ms/step\n",
      "Epoch 215/700\n",
      "\n",
      "Epoch 215: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3656 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4552 - 8s/epoch - 56ms/step\n",
      "Epoch 216/700\n",
      "\n",
      "Epoch 216: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5849 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1950 - val_loss: 4.3628 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4543 - 8s/epoch - 56ms/step\n",
      "Epoch 217/700\n",
      "\n",
      "Epoch 217: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3761 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4587 - 8s/epoch - 56ms/step\n",
      "Epoch 218/700\n",
      "\n",
      "Epoch 218: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5847 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3649 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4550 - 8s/epoch - 56ms/step\n",
      "Epoch 219/700\n",
      "\n",
      "Epoch 219: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3596 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4532 - 9s/epoch - 57ms/step\n",
      "Epoch 220/700\n",
      "\n",
      "Epoch 220: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3772 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4591 - 9s/epoch - 56ms/step\n",
      "Epoch 221/700\n",
      "\n",
      "Epoch 221: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 8s - loss: 0.5848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3712 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4571 - 8s/epoch - 56ms/step\n",
      "Epoch 222/700\n",
      "\n",
      "Epoch 222: val_ws_predictor_loss did not improve from 1.45315\n",
      "151/151 - 9s - loss: 0.5847 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1949 - val_loss: 4.3636 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.4545 - 9s/epoch - 57ms/step\n",
      "Epoch 223/700\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 20\u001b[0m\n\u001b[1;32m     11\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m     12\u001b[0m mc \u001b[38;5;241m=\u001b[39m ModelCheckpoint(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../saved_models/gcn_gtnp_1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_hours, K),\n\u001b[1;32m     13\u001b[0m                      monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_ws_predictor_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     14\u001b[0m                      mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     15\u001b[0m                      verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, \n\u001b[1;32m     16\u001b[0m                      custom_objects\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgate_loss\u001b[39m\u001b[38;5;124m'\u001b[39m:gate_loss, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwater_level_threshold\u001b[39m\u001b[38;5;124m'\u001b[39m:water_level_threshold}, \n\u001b[1;32m     17\u001b[0m                      save_best_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfilda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_X_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adj_mat_gcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_tws_reshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_adj_mat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_gate_pump_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_ws_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_X_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_adj_mat_gcn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_tws_reshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_adj_mat\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mval_gate_pump_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_ws_y\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m plt\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure.figsize\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[1;32m     31\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mws_predictor_loss\u001b[39m\u001b[38;5;124m'\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf213/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "                                                          decay_steps=decay_steps,\n",
    "                                                          decay_rate=decay_rate)\n",
    "\n",
    "filda.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "              loss=[gate_loss, water_level_threshold], \n",
    "              loss_weights=[0.0, 3.0]\n",
    "             )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=100)\n",
    "mc = ModelCheckpoint('../saved_models/gcn_gtnp_1.h5'.format(n_hours, K),\n",
    "                     monitor='val_ws_predictor_loss',\n",
    "                     mode='min',\n",
    "                     verbose=2, \n",
    "                     custom_objects={'gate_loss':gate_loss, 'water_level_threshold':water_level_threshold}, \n",
    "                     save_best_only=True)\n",
    "\n",
    "\n",
    "history = filda.fit([train_X_mask, train_adj_mat_gcn, train_tws_reshape, train_adj_mat], [train_gate_pump_y, train_ws_y],\n",
    "                   validation_data=([val_X_mask, val_adj_mat_gcn, val_tws_reshape, val_adj_mat], [val_gate_pump_y, val_ws_y]),\n",
    "                   batch_size=BATCH, \n",
    "                   epochs=EPOCHS, \n",
    "                   verbose=2, \n",
    "                   callbacks=[es, mc],\n",
    "                   shuffle=True,\n",
    "                  )\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6, 4)\n",
    "plt.plot(history.history['ws_predictor_loss'], label='train')\n",
    "plt.plot(history.history['val_ws_predictor_loss'], label='val')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Training loss vs Testing loss\", fontsize=18)\n",
    "# plt.savefig('graph/rnn_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274afc23",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c761507a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "saved_model = load_model('../saved_models/gcn_gtnp_1.h5',\n",
    "                         custom_objects={'gate_loss':gate_loss, \n",
    "                                         'water_level_threshold':water_level_threshold,\n",
    "                                         'GCNConv': GCNConv\n",
    "                                        }\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "437232bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 17:14:40.213486: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 6s 7ms/step\n",
      "(19268, 24, 7)\n",
      "(19268, 96)\n",
      "Usded time: 7.268814068287611 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "\n",
    "\n",
    "gate_pump_pred, ws_pred = saved_model.predict([test_X_mask, test_adj_mat_gcn, test_tws_reshape, test_adj_mat])\n",
    "\n",
    "print(gate_pump_pred.shape)\n",
    "print(ws_pred.shape)\n",
    "\n",
    "\n",
    "end_time = time.perf_counter()\n",
    "used_time = end_time - start_time\n",
    "print(f\"Usded time: {used_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd7424",
   "metadata": {},
   "source": [
    "#### ws pred, gate pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73063d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_pred_gate_pred_inv = ws_scaler.inverse_transform(ws_pred)\n",
    "ws_pred_gate_pred_inv = ws_pred_gate_pred_inv.reshape((-1, K, 4))\n",
    "ws_pred_gate_pred_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b7677",
   "metadata": {},
   "source": [
    "#### ws true, gate true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc62a508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_true_gate_true = test_ws_y\n",
    "ws_true_gate_true_inv = ws_scaler.inverse_transform(ws_true_gate_true)\n",
    "ws_true_gate_true_inv = ws_true_gate_true_inv.reshape((-1, K, 4))\n",
    "ws_true_gate_true_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa81cf7",
   "metadata": {},
   "source": [
    "#### ws pred, gate true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb27e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "603/603 [==============================] - 3s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_predictor = load_model('../saved_models/WaLeF_gtn_p.h5', custom_objects={'GCNConv': GCNConv})\n",
    "\n",
    "ws_pred_gate_true = ws_predictor.predict([test_cov, test_tws_reshape, test_adj_mat])\n",
    "ws_pred_gate_true_inv = ws_scaler.inverse_transform(ws_pred_gate_true)\n",
    "ws_pred_gate_true_inv = ws_pred_gate_true_inv.reshape((-1, 24, 4))\n",
    "ws_pred_gate_true_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36fbd5",
   "metadata": {},
   "source": [
    "### Upper threshould"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e17b717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 96, 96, 118, 117\n",
      "S1, S25A, S25B, S26 areas: 14.82, 15.22, 18, 20.13\n",
      "TOTAL time steps: 427; TOTAL areas: 68.61\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 85, 85, 96, 108\n",
      "S1, S25A, S25B, S26 areas: 11.5466, 12.1773, 13, 17.2181\n",
      "TOTAL time steps: 374; TOTAL areas: 54.3063\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 31, 52, 53, 45\n",
      "S1, S25A, S25B, S26 areas: 3.7296, 6.8456, 8, 6.6839\n",
      "TOTAL time steps: 181; TOTAL areas: 25.0683\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "upper_threshold = 3.5\n",
    "t1 = 1\n",
    "\n",
    "flood_threshold_t1(ws_true_gate_true_inv, t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_true_inv, t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_pred_inv, t1, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35bbbfea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 6, 5, 6, 6\n",
      "S1, S25A, S25B, S26 areas: 0.84, 0.72, 1, 1.0\n",
      "TOTAL time steps: 23; TOTAL areas: 3.62\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 6, 6, 5, 5\n",
      "S1, S25A, S25B, S26 areas: 0.6148, 0.6425, 1, 0.8663\n",
      "TOTAL time steps: 22; TOTAL areas: 3.0018\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 2, 1, 1, 2\n",
      "S1, S25A, S25B, S26 areas: 0.0625, 0.0478, 0, 0.14\n",
      "TOTAL time steps: 6; TOTAL areas: 0.3257\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "flood_threshold_t1(ws_true_gate_true_inv[7640-23:7680-23], t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_true_inv[7640-23:7680-23], t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_pred_inv[7640-23:7680-23], t1, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cae8935e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 10248, areas: 1646.6399002075195\n",
      "time steps: 12130, areas: 2088.0380942821503\n",
      "time steps: 8780, areas: 1458.1937358379364\n"
     ]
    }
   ],
   "source": [
    "flood_threshold(ws_true_gate_true_inv, upper_threshold)\n",
    "flood_threshold(ws_pred_gate_true_inv, upper_threshold)\n",
    "flood_threshold(ws_pred_gate_pred_inv, upper_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e11a6",
   "metadata": {},
   "source": [
    "### Lower threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1391897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 1346, 1341, 1229, 1250\n",
      "S1, S25A, S25B, S26 areas: -385.8, -383.38, -345.08, -350.84:\n",
      "TOTAL time steps: 5166; TOTAL areas: -1465.1\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 1390, 1427, 1282, 1476\n",
      "S1, S25A, S25B, S26 areas: -398.849, -392.0414, -350.2885, -429.5386:\n",
      "TOTAL time steps: 5575; TOTAL areas: -1570.7176\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 429, 302, 150, 228\n",
      "S1, S25A, S25B, S26 areas: -84.3139, -61.0771, -22.0615, -40.0315:\n",
      "TOTAL time steps: 1109; TOTAL areas: -207.484\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lower_threshold = 0\n",
    "t1 = 1\n",
    "\n",
    "drought_threshold_t1(ws_true_gate_true_inv, t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_true_inv, t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_pred_inv, t1, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ef4a0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 124148, areas: 35182.6098122485\n",
      "time steps: 127126, areas: 34960.07284716559\n",
      "time steps: 25699, areas: 5103.557413006052\n"
     ]
    }
   ],
   "source": [
    "lower_threshold = 0\n",
    "\n",
    "drought_threshold(ws_true_gate_true_inv, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_true_inv, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_pred_inv, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad10809e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098eb21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ccc1f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
