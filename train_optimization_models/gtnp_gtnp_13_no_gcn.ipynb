{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "efa98cb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 12:30:50.996476: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 12:30:52.499595: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714025946899135\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "current_directory = os.getcwd()        \n",
    "parent_directory = os.path.dirname(current_directory)\n",
    "sys.path.append(parent_directory)\n",
    "\n",
    "\n",
    "from preprocess.graph import graph_topology_5\n",
    "from preprocess.GraphTransformerPrerocess import graph_water_transformer_cov_process_for_gate_predictor\n",
    "from models.graph_water_transformer_cov_no_gcn import graph_water_transformer_cov_gate_predictor_no_gcn\n",
    "\n",
    "from losses.loss import gate_loss, water_level_threshold\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from postprocess.threshold import flood_threshold, drought_threshold, flood_threshold_t1, drought_threshold_t1\n",
    "\n",
    "\n",
    "import random\n",
    "\n",
    "random.seed(10)\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0092be29",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b8077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hours = 72\n",
    "K = 24 \n",
    "masked_value = 1e-10\n",
    "split_1 = 0.8\n",
    "split_2 = 0.9\n",
    "sigma2 = 0.1\n",
    "epsilon = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43bd0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WS_S1', 'WS_S4', 'FLOW_S25A', 'GATE_S25A', 'HWS_S25A', 'TWS_S25A',\n",
      "       'FLOW_S25B', 'GATE_S25B', 'GATE_S25B2', 'HWS_S25B', 'TWS_S25B',\n",
      "       'PUMP_S25B', 'FLOW_S26', 'GATE_S26_1', 'GATE_S26_2', 'HWS_S26',\n",
      "       'TWS_S26', 'PUMP_S26', 'MEAN_RAIN'],\n",
      "      dtype='object')\n",
      "train_tws/val_tws/test_tws: (77069, 5, 72) (9634, 5, 72) (19268, 5, 72) \n",
      " train_cov/val_cov/test_cov: (77069, 96, 12) (9634, 96, 12) (19268, 96, 12) \n",
      " train_ws_y/val_ws_y/test_ws_y: (77069, 96) (9634, 96) (19268, 96) \n",
      "  train_gate_pump_y/val_gate_pump_y/test_gate_pump_y: (77069, 24, 7) (9634, 24, 7) (19268, 24, 7)\n"
     ]
    }
   ],
   "source": [
    "train_cov, val_cov, test_cov, \\\n",
    "train_tws_reshape, val_tws_reshape, test_tws_reshape, \\\n",
    "train_gate_pump_y, val_gate_pump_y, test_gate_pump_y, \\\n",
    "train_ws_y, val_ws_y, test_ws_y, \\\n",
    "scaler, ws_scaler, gate_scalar = graph_water_transformer_cov_process_for_gate_predictor(n_hours, K, masked_value, split_1, split_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265ed7ff",
   "metadata": {},
   "source": [
    "### Graph topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e803d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_indices: [0 0 0 0 1 1 2 2 3 3 4 4] \n",
      "neighbor_indices: [1 2 3 4 0 2 0 1 0 4 0 3]\n",
      "number of nodes: 5, number of edges: 12\n"
     ]
    }
   ],
   "source": [
    "train_adj_mat, val_adj_mat, test_adj_mat = graph_topology_5(n_hours, K, sigma2, epsilon, len(train_ws_y), len(val_ws_y), len(test_ws_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8003a2dc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4861afcd",
   "metadata": {},
   "source": [
    "#### Gate & pump predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdfb0ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== model parameters ======\n",
    "head_size = 96*2\n",
    "num_heads = 3\n",
    "ff_dim = 96\n",
    "num_transformer_blocks = 1\n",
    "dropout = 0.5\n",
    "atte_reg = 1e-2\n",
    "l1_reg = 1e-5\n",
    "l2_reg = 1e-5\n",
    "gcn_unit1 = 32\n",
    "gcn_unit2 = 16\n",
    "lstm_units = 32\n",
    "gate_min = 0.0\n",
    "gate_max = 1.0\n",
    "\n",
    "learning_rate = 3e-3\n",
    "decay_steps = 10000\n",
    "decay_rate = 0.95\n",
    "PATIENCE = 100\n",
    "EPOCHS = 700\n",
    "BATCH = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9ace5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_cov.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109abeeb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 12:31:02.097666: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10402 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1080 Ti, pci bus id: 0000:08:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"gate_predictor\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " cov_inputs (InputLayer)     [(None, 96, 12)]             0         []                            \n",
      "                                                                                                  \n",
      " masking (Masking)           (None, 96, 12)               0         ['cov_inputs[0][0]']          \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, 96, 12)               29388     ['masking[0][0]',             \n",
      " iHeadAttention)                                                     'masking[0][0]']             \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 96, 12)               0         ['multi_head_attention[0][0]']\n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, 96, 12)               0         ['dropout[0][0]',             \n",
      " Lambda)                                                             'masking[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, 96, 12)               24        ['tf.__operators__.add[0][0]']\n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)             (None, 96, 96)               2400      ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 96, 96)               0         ['conv1d[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)           (None, 96, 12)               2316      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, 96, 12)               24        ['conv1d_1[0][0]']            \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " inp_seq (InputLayer)        [(None, 5, 72)]              0         []                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, 96, 12)               0         ['layer_normalization_1[0][0]'\n",
      " OpLambda)                                                          , 'tf.__operators__.add[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " inp_seq_reshape (Reshape)   (None, 72, 5)                0         ['inp_seq[0][0]']             \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 96, 32)               416       ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " LSTM (LSTM)                 (None, 72, 32)               4864      ['inp_seq_reshape[0][0]']     \n",
      "                                                                                                  \n",
      " pooling1 (MaxPooling1D)     (None, 48, 32)               0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " pooling2 (MaxPooling1D)     (None, 36, 32)               0         ['LSTM[0][0]']                \n",
      "                                                                                                  \n",
      " concate (Concatenate)       (None, 84, 32)               0         ['pooling1[0][0]',            \n",
      "                                                                     'pooling2[0][0]']            \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 84, 32)               0         ['concate[0][0]',             \n",
      "                                                                     'concate[0][0]']             \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 84, 7)                231       ['attention[0][0]']           \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 588)                  0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 168)                  98952     ['flatten[0][0]']             \n",
      "                                                                                                  \n",
      " reshape (Reshape)           (None, 24, 7)                0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.maximum (TFOpLambd  (None, 24, 7)                0         ['reshape[0][0]']             \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.minimum (TFOpLambd  (None, 24, 7)                0         ['tf.math.maximum[0][0]']     \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 138615 (541.46 KB)\n",
      "Trainable params: 138615 (541.46 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gate_predictor, GCNConv = graph_water_transformer_cov_gate_predictor_no_gcn(input_shape=input_shape,\n",
    "                                                                            lstm_unit=lstm_units, \n",
    "                                                                            num_transformer_blocks=num_transformer_blocks, \n",
    "                                                                            head_size=head_size, \n",
    "                                                                            num_heads=num_heads, \n",
    "                                                                            ff_dim=ff_dim, \n",
    "                                                                            atte_reg=atte_reg, \n",
    "                                                                            l1_reg=l1_reg, \n",
    "                                                                            l2_reg=l2_reg, \n",
    "                                                                            dropout=dropout,\n",
    "                                                                            masked_value=masked_value,\n",
    "                                                                            gate_min=gate_min,\n",
    "                                                                            gate_max=gate_max,\n",
    "                                                                           )\n",
    "gate_predictor._name = \"gate_predictor\"\n",
    "gate_predictor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7023c4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "gate_predictor.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fab7c93",
   "metadata": {},
   "source": [
    "#### water stage predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8002ff9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "ws_predictor = load_model('../saved_models/WaLeF_gtn_p.h5', custom_objects={'GCNConv': GCNConv})\n",
    "\n",
    "for layer in ws_predictor.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "ws_predictor._name = 'ws_predictor'    \n",
    "# ws_predictor.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733bce1a",
   "metadata": {},
   "source": [
    "#### Combine gate_predictor and trained ws_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850a59ca",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "inputs_cov = Input(shape=(96, 12), name='input_cov')\n",
    "inputs_tws = Input(shape=(5, 72), name='input_tws')\n",
    "inputs_adj = Input(shape=(5, 5), name='input_adj')\n",
    "\n",
    "# ================ gate_predictor ================\n",
    "gate_predictor_output = gate_predictor([inputs_cov, inputs_tws])  # 24*7\n",
    "\n",
    "\n",
    "# ============  future inputs with replaced gate & pump prediction ============\n",
    "replaced_future_gate_pump = layers.Concatenate(axis=-1)([inputs_cov[:, n_hours:, :2], \n",
    "                                                         gate_predictor_output, \n",
    "                                                         inputs_cov[:, n_hours:, 9:]\n",
    "                                                        ]\n",
    "                                                       )\n",
    "\n",
    "# ============ original past inputs + future inputs with replaced gate & pump prediction ============\n",
    "merged_inputs_cov = layers.Concatenate(axis=1)([inputs_cov[:, :n_hours, :], replaced_future_gate_pump])\n",
    "\n",
    "ws_predictor_output = ws_predictor([merged_inputs_cov, inputs_tws, inputs_adj])\n",
    "\n",
    "filda = Model(inputs=[inputs_cov, inputs_tws, inputs_adj], outputs=[gate_predictor_output, ws_predictor_output], name='filda')\n",
    "# filda.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf907f2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 12:31:20.832168: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2023-08-12 12:31:22.244215: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2ed6027760 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-08-12 12:31:22.244264: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1080 Ti, Compute Capability 6.1\n",
      "2023-08-12 12:31:22.253637: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-08-12 12:31:22.669467: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_ws_predictor_loss improved from inf to 3.05294, saving model to ../saved_models/gtnp_gtnp_13_no_gcn.h5\n",
      "151/151 - 38s - loss: 0.5016 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2383 - val_loss: 6.1092 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 3.0529 - 38s/epoch - 253ms/step\n",
      "Epoch 2/700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/aul/homes/jshi008/miniconda3/envs/tf213/lib/python3.10/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2: val_ws_predictor_loss did not improve from 3.05294\n",
      "151/151 - 21s - loss: 0.4791 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2381 - val_loss: 6.4781 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 3.2379 - 21s/epoch - 141ms/step\n",
      "Epoch 3/700\n",
      "\n",
      "Epoch 3: val_ws_predictor_loss improved from 3.05294 to 1.83432, saving model to ../saved_models/gtnp_gtnp_13_no_gcn.h5\n",
      "151/151 - 21s - loss: 0.4620 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2299 - val_loss: 3.6714 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.8343 - 21s/epoch - 142ms/step\n",
      "Epoch 4/700\n",
      "\n",
      "Epoch 4: val_ws_predictor_loss improved from 1.83432 to 1.60879, saving model to ../saved_models/gtnp_gtnp_13_no_gcn.h5\n",
      "151/151 - 21s - loss: 0.4032 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.2004 - val_loss: 3.2197 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6088 - 21s/epoch - 140ms/step\n",
      "Epoch 5/700\n",
      "\n",
      "Epoch 5: val_ws_predictor_loss improved from 1.60879 to 1.59679, saving model to ../saved_models/gtnp_gtnp_13_no_gcn.h5\n",
      "151/151 - 21s - loss: 0.3968 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1974 - val_loss: 3.1955 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.5968 - 21s/epoch - 140ms/step\n",
      "Epoch 6/700\n",
      "\n",
      "Epoch 6: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3935 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1958 - val_loss: 3.2362 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6172 - 21s/epoch - 140ms/step\n",
      "Epoch 7/700\n",
      "\n",
      "Epoch 7: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3940 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1960 - val_loss: 3.3211 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6565 - 21s/epoch - 139ms/step\n",
      "Epoch 8/700\n",
      "\n",
      "Epoch 8: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3928 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1953 - val_loss: 3.2582 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6283 - 21s/epoch - 139ms/step\n",
      "Epoch 9/700\n",
      "\n",
      "Epoch 9: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3896 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1941 - val_loss: 3.2573 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6279 - 21s/epoch - 140ms/step\n",
      "Epoch 10/700\n",
      "\n",
      "Epoch 10: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3885 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1935 - val_loss: 3.2533 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6260 - 21s/epoch - 139ms/step\n",
      "Epoch 11/700\n",
      "\n",
      "Epoch 11: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3880 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1933 - val_loss: 3.2157 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6072 - 21s/epoch - 142ms/step\n",
      "Epoch 12/700\n",
      "\n",
      "Epoch 12: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 22s - loss: 0.3872 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1930 - val_loss: 3.3090 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6539 - 22s/epoch - 143ms/step\n",
      "Epoch 13/700\n",
      "\n",
      "Epoch 13: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 22s - loss: 0.3866 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1927 - val_loss: 3.2785 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6386 - 22s/epoch - 143ms/step\n",
      "Epoch 14/700\n",
      "\n",
      "Epoch 14: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3861 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1925 - val_loss: 3.3182 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6586 - 21s/epoch - 141ms/step\n",
      "Epoch 15/700\n",
      "\n",
      "Epoch 15: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1923 - val_loss: 3.4092 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7041 - 21s/epoch - 140ms/step\n",
      "Epoch 16/700\n",
      "\n",
      "Epoch 16: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3910 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1945 - val_loss: 3.4123 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7051 - 21s/epoch - 142ms/step\n",
      "Epoch 17/700\n",
      "\n",
      "Epoch 17: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3867 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1927 - val_loss: 3.4493 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7242 - 21s/epoch - 141ms/step\n",
      "Epoch 18/700\n",
      "\n",
      "Epoch 18: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1921 - val_loss: 3.3451 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6720 - 21s/epoch - 141ms/step\n",
      "Epoch 19/700\n",
      "\n",
      "Epoch 19: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3845 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1918 - val_loss: 3.4551 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7271 - 21s/epoch - 140ms/step\n",
      "Epoch 20/700\n",
      "\n",
      "Epoch 20: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3872 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1930 - val_loss: 3.4349 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7157 - 21s/epoch - 141ms/step\n",
      "Epoch 21/700\n",
      "\n",
      "Epoch 21: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3859 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1923 - val_loss: 3.4750 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7370 - 21s/epoch - 141ms/step\n",
      "Epoch 22/700\n",
      "\n",
      "Epoch 22: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3839 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1915 - val_loss: 3.3997 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6994 - 21s/epoch - 141ms/step\n",
      "Epoch 23/700\n",
      "\n",
      "Epoch 23: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3836 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1914 - val_loss: 3.5079 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7536 - 21s/epoch - 140ms/step\n",
      "Epoch 24/700\n",
      "\n",
      "Epoch 24: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3833 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1912 - val_loss: 3.4212 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7102 - 21s/epoch - 142ms/step\n",
      "Epoch 25/700\n",
      "\n",
      "Epoch 25: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3863 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1926 - val_loss: 3.4221 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7104 - 21s/epoch - 142ms/step\n",
      "Epoch 26/700\n",
      "\n",
      "Epoch 26: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3843 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1917 - val_loss: 3.5058 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7524 - 21s/epoch - 141ms/step\n",
      "Epoch 27/700\n",
      "\n",
      "Epoch 27: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3831 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1912 - val_loss: 3.4551 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7272 - 21s/epoch - 141ms/step\n",
      "Epoch 28/700\n",
      "\n",
      "Epoch 28: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3829 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1911 - val_loss: 3.4670 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7331 - 21s/epoch - 141ms/step\n",
      "Epoch 29/700\n",
      "\n",
      "Epoch 29: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3829 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1911 - val_loss: 3.4596 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7295 - 21s/epoch - 141ms/step\n",
      "Epoch 30/700\n",
      "\n",
      "Epoch 30: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3879 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1932 - val_loss: 3.4699 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7344 - 21s/epoch - 139ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/700\n",
      "\n",
      "Epoch 31: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3836 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1914 - val_loss: 3.5488 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7740 - 21s/epoch - 142ms/step\n",
      "Epoch 32/700\n",
      "\n",
      "Epoch 32: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3828 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1910 - val_loss: 3.4680 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7336 - 21s/epoch - 140ms/step\n",
      "Epoch 33/700\n",
      "\n",
      "Epoch 33: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3827 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1910 - val_loss: 3.5211 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7602 - 21s/epoch - 140ms/step\n",
      "Epoch 34/700\n",
      "\n",
      "Epoch 34: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3825 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.4962 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7478 - 21s/epoch - 139ms/step\n",
      "Epoch 35/700\n",
      "\n",
      "Epoch 35: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3826 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.5166 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7580 - 21s/epoch - 141ms/step\n",
      "Epoch 36/700\n",
      "\n",
      "Epoch 36: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3917 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1948 - val_loss: 3.6259 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.8104 - 21s/epoch - 141ms/step\n",
      "Epoch 37/700\n",
      "\n",
      "Epoch 37: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3906 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1942 - val_loss: 3.4041 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7015 - 21s/epoch - 141ms/step\n",
      "Epoch 38/700\n",
      "\n",
      "Epoch 38: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3846 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1919 - val_loss: 3.3853 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6922 - 21s/epoch - 141ms/step\n",
      "Epoch 39/700\n",
      "\n",
      "Epoch 39: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3834 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1913 - val_loss: 3.4137 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7065 - 21s/epoch - 140ms/step\n",
      "Epoch 40/700\n",
      "\n",
      "Epoch 40: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3830 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1911 - val_loss: 3.4213 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7103 - 21s/epoch - 140ms/step\n",
      "Epoch 41/700\n",
      "\n",
      "Epoch 41: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3825 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.4225 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7109 - 21s/epoch - 140ms/step\n",
      "Epoch 42/700\n",
      "\n",
      "Epoch 42: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3825 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.4042 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7018 - 21s/epoch - 142ms/step\n",
      "Epoch 43/700\n",
      "\n",
      "Epoch 43: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3823 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1908 - val_loss: 3.4056 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7025 - 21s/epoch - 140ms/step\n",
      "Epoch 44/700\n",
      "\n",
      "Epoch 44: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3824 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.3814 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6904 - 21s/epoch - 139ms/step\n",
      "Epoch 45/700\n",
      "\n",
      "Epoch 45: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3822 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1908 - val_loss: 3.3905 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6949 - 21s/epoch - 140ms/step\n",
      "Epoch 46/700\n",
      "\n",
      "Epoch 46: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3825 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.3916 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6955 - 21s/epoch - 141ms/step\n",
      "Epoch 47/700\n",
      "\n",
      "Epoch 47: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3820 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4044 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7019 - 21s/epoch - 140ms/step\n",
      "Epoch 48/700\n",
      "\n",
      "Epoch 48: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3821 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4066 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7030 - 21s/epoch - 141ms/step\n",
      "Epoch 49/700\n",
      "\n",
      "Epoch 49: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3821 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1908 - val_loss: 3.4121 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7058 - 21s/epoch - 139ms/step\n",
      "Epoch 50/700\n",
      "\n",
      "Epoch 50: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3837 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1915 - val_loss: 3.3870 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6921 - 21s/epoch - 140ms/step\n",
      "Epoch 51/700\n",
      "\n",
      "Epoch 51: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3837 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1914 - val_loss: 3.4179 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7087 - 21s/epoch - 140ms/step\n",
      "Epoch 52/700\n",
      "\n",
      "Epoch 52: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3819 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4060 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7027 - 21s/epoch - 141ms/step\n",
      "Epoch 53/700\n",
      "\n",
      "Epoch 53: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3819 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3913 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6954 - 21s/epoch - 140ms/step\n",
      "Epoch 54/700\n",
      "\n",
      "Epoch 54: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.4110 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7052 - 21s/epoch - 138ms/step\n",
      "Epoch 55/700\n",
      "\n",
      "Epoch 55: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3841 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1915 - val_loss: 3.3931 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6962 - 21s/epoch - 140ms/step\n",
      "Epoch 56/700\n",
      "\n",
      "Epoch 56: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3820 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4234 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7114 - 21s/epoch - 140ms/step\n",
      "Epoch 57/700\n",
      "\n",
      "Epoch 57: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.4194 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7094 - 21s/epoch - 138ms/step\n",
      "Epoch 58/700\n",
      "\n",
      "Epoch 58: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3817 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3971 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6983 - 21s/epoch - 140ms/step\n",
      "Epoch 59/700\n",
      "\n",
      "Epoch 59: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.4084 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7039 - 21s/epoch - 140ms/step\n",
      "Epoch 60/700\n",
      "\n",
      "Epoch 60: val_ws_predictor_loss did not improve from 1.59679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3972 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6983 - 21s/epoch - 140ms/step\n",
      "Epoch 61/700\n",
      "\n",
      "Epoch 61: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3821 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4115 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7055 - 21s/epoch - 139ms/step\n",
      "Epoch 62/700\n",
      "\n",
      "Epoch 62: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3817 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3899 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6947 - 21s/epoch - 139ms/step\n",
      "Epoch 63/700\n",
      "\n",
      "Epoch 63: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3817 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3756 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6875 - 21s/epoch - 139ms/step\n",
      "Epoch 64/700\n",
      "\n",
      "Epoch 64: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4001 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6997 - 21s/epoch - 139ms/step\n",
      "Epoch 65/700\n",
      "\n",
      "Epoch 65: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4152 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7073 - 21s/epoch - 140ms/step\n",
      "Epoch 66/700\n",
      "\n",
      "Epoch 66: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3862 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1925 - val_loss: 3.3410 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6694 - 21s/epoch - 140ms/step\n",
      "Epoch 67/700\n",
      "\n",
      "Epoch 67: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3835 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1913 - val_loss: 3.4129 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7061 - 21s/epoch - 141ms/step\n",
      "Epoch 68/700\n",
      "\n",
      "Epoch 68: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.4076 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7035 - 21s/epoch - 140ms/step\n",
      "Epoch 69/700\n",
      "\n",
      "Epoch 69: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4236 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7115 - 21s/epoch - 139ms/step\n",
      "Epoch 70/700\n",
      "\n",
      "Epoch 70: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3760 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6877 - 21s/epoch - 138ms/step\n",
      "Epoch 71/700\n",
      "\n",
      "Epoch 71: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3885 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6940 - 21s/epoch - 138ms/step\n",
      "Epoch 72/700\n",
      "\n",
      "Epoch 72: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3926 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6960 - 21s/epoch - 140ms/step\n",
      "Epoch 73/700\n",
      "\n",
      "Epoch 73: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3942 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6968 - 21s/epoch - 141ms/step\n",
      "Epoch 74/700\n",
      "\n",
      "Epoch 74: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3848 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1918 - val_loss: 3.3702 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6848 - 21s/epoch - 140ms/step\n",
      "Epoch 75/700\n",
      "\n",
      "Epoch 75: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3826 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6910 - 21s/epoch - 139ms/step\n",
      "Epoch 76/700\n",
      "\n",
      "Epoch 76: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3857 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6926 - 21s/epoch - 140ms/step\n",
      "Epoch 77/700\n",
      "\n",
      "Epoch 77: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3814 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3967 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6981 - 21s/epoch - 140ms/step\n",
      "Epoch 78/700\n",
      "\n",
      "Epoch 78: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3852 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1921 - val_loss: 3.4487 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7234 - 21s/epoch - 139ms/step\n",
      "Epoch 79/700\n",
      "\n",
      "Epoch 79: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1924 - val_loss: 3.4068 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7030 - 21s/epoch - 139ms/step\n",
      "Epoch 80/700\n",
      "\n",
      "Epoch 80: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3826 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1909 - val_loss: 3.3729 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6861 - 21s/epoch - 139ms/step\n",
      "Epoch 81/700\n",
      "\n",
      "Epoch 81: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3820 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.3653 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6823 - 21s/epoch - 140ms/step\n",
      "Epoch 82/700\n",
      "\n",
      "Epoch 82: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3880 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6937 - 21s/epoch - 139ms/step\n",
      "Epoch 83/700\n",
      "\n",
      "Epoch 83: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4051 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7023 - 21s/epoch - 139ms/step\n",
      "Epoch 84/700\n",
      "\n",
      "Epoch 84: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3840 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6918 - 21s/epoch - 139ms/step\n",
      "Epoch 85/700\n",
      "\n",
      "Epoch 85: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3814 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3780 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6887 - 21s/epoch - 141ms/step\n",
      "Epoch 86/700\n",
      "\n",
      "Epoch 86: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3857 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1923 - val_loss: 3.4562 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7275 - 21s/epoch - 139ms/step\n",
      "Epoch 87/700\n",
      "\n",
      "Epoch 87: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3851 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1922 - val_loss: 3.4683 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7337 - 21s/epoch - 139ms/step\n",
      "Epoch 88/700\n",
      "\n",
      "Epoch 88: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3827 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1910 - val_loss: 3.4293 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7143 - 21s/epoch - 140ms/step\n",
      "Epoch 89/700\n",
      "\n",
      "Epoch 89: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3820 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4326 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7160 - 21s/epoch - 138ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/700\n",
      "\n",
      "Epoch 90: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3818 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1906 - val_loss: 3.3800 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6897 - 21s/epoch - 139ms/step\n",
      "Epoch 91/700\n",
      "\n",
      "Epoch 91: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3816 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4057 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7026 - 21s/epoch - 138ms/step\n",
      "Epoch 92/700\n",
      "\n",
      "Epoch 92: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.3617 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6806 - 21s/epoch - 138ms/step\n",
      "Epoch 93/700\n",
      "\n",
      "Epoch 93: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3834 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1913 - val_loss: 3.3883 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6939 - 21s/epoch - 138ms/step\n",
      "Epoch 94/700\n",
      "\n",
      "Epoch 94: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4216 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7105 - 21s/epoch - 138ms/step\n",
      "Epoch 95/700\n",
      "\n",
      "Epoch 95: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3814 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.3992 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6994 - 21s/epoch - 139ms/step\n",
      "Epoch 96/700\n",
      "\n",
      "Epoch 96: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3814 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.3870 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6933 - 21s/epoch - 138ms/step\n",
      "Epoch 97/700\n",
      "\n",
      "Epoch 97: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3813 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.4179 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7087 - 21s/epoch - 139ms/step\n",
      "Epoch 98/700\n",
      "\n",
      "Epoch 98: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3842 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1916 - val_loss: 3.3513 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.6751 - 21s/epoch - 140ms/step\n",
      "Epoch 99/700\n",
      "\n",
      "Epoch 99: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3819 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1907 - val_loss: 3.4295 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7145 - 21s/epoch - 140ms/step\n",
      "Epoch 100/700\n",
      "\n",
      "Epoch 100: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3814 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4164 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7079 - 21s/epoch - 138ms/step\n",
      "Epoch 101/700\n",
      "\n",
      "Epoch 101: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3815 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1905 - val_loss: 3.4024 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7010 - 21s/epoch - 139ms/step\n",
      "Epoch 102/700\n",
      "\n",
      "Epoch 102: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3813 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.4250 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7122 - 21s/epoch - 139ms/step\n",
      "Epoch 103/700\n",
      "\n",
      "Epoch 103: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3813 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.4273 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7134 - 21s/epoch - 140ms/step\n",
      "Epoch 104/700\n",
      "\n",
      "Epoch 104: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3813 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.4278 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7136 - 21s/epoch - 141ms/step\n",
      "Epoch 105/700\n",
      "\n",
      "Epoch 105: val_ws_predictor_loss did not improve from 1.59679\n",
      "151/151 - 21s - loss: 0.3813 - gate_predictor_loss: 0.0000e+00 - ws_predictor_loss: 0.1904 - val_loss: 3.4084 - val_gate_predictor_loss: 0.0000e+00 - val_ws_predictor_loss: 1.7040 - 21s/epoch - 139ms/step\n",
      "Epoch 105: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=learning_rate, \n",
    "                                                          decay_steps=decay_steps,\n",
    "                                                          decay_rate=decay_rate)\n",
    "\n",
    "filda.compile(optimizer=Adam(learning_rate=lr_schedule),\n",
    "             loss=[gate_loss, water_level_threshold], \n",
    "             loss_weights=[0.0, 2.0]\n",
    "            )\n",
    "\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=100)\n",
    "mc = ModelCheckpoint('../saved_models/gtnp_gtnp_13_no_gcn.h5'.format(n_hours, K),\n",
    "                     monitor='val_ws_predictor_loss',\n",
    "                     mode='min',\n",
    "                     verbose=2, \n",
    "                     custom_objects={'gate_loss':gate_loss, 'water_level_threshold':water_level_threshold}, \n",
    "                     save_best_only=True)\n",
    "\n",
    "\n",
    "history = filda.fit([train_cov, train_tws_reshape, train_adj_mat], [train_gate_pump_y, train_ws_y],\n",
    "                   validation_data=([val_cov, val_tws_reshape, val_adj_mat], [val_gate_pump_y, val_ws_y]),\n",
    "                   batch_size=BATCH, \n",
    "                   epochs=EPOCHS, \n",
    "                   verbose=2, \n",
    "                   callbacks=[es, mc],\n",
    "                   shuffle=True,\n",
    "                  )\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 6)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Training loss vs Testing loss\", fontsize=18)\n",
    "# plt.savefig('graph/rnn_loss.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274afc23",
   "metadata": {},
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c761507a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "saved_model = load_model('../saved_models/gtnp_gtnp_13_no_gcn.h5',\n",
    "                         custom_objects={'gate_loss':gate_loss, \n",
    "                                         'water_level_threshold':water_level_threshold,\n",
    "                                         'GCNConv': GCNConv\n",
    "                                        }\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "437232bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 12s 18ms/step\n",
      "(19268, 24, 7)\n",
      "(19268, 96)\n"
     ]
    }
   ],
   "source": [
    "gate_pump_pred, ws_pred = saved_model.predict([test_cov, test_tws_reshape, test_adj_mat])\n",
    "\n",
    "print(gate_pump_pred.shape)\n",
    "print(ws_pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37fd7424",
   "metadata": {},
   "source": [
    "#### ws pred, gate pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73063d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_pred_gate_pred_inv = ws_scaler.inverse_transform(ws_pred)\n",
    "ws_pred_gate_pred_inv = ws_pred_gate_pred_inv.reshape((-1, K, 4))\n",
    "ws_pred_gate_pred_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181b7677",
   "metadata": {},
   "source": [
    "#### ws true, gate true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc62a508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_true_gate_true = test_ws_y\n",
    "ws_true_gate_true_inv = ws_scaler.inverse_transform(ws_true_gate_true)\n",
    "ws_true_gate_true_inv = ws_true_gate_true_inv.reshape((-1, K, 4))\n",
    "ws_true_gate_true_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa81cf7",
   "metadata": {},
   "source": [
    "#### ws pred, gate true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb27e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer LSTM will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "603/603 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(19268, 24, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ws_predictor = load_model('../saved_models/WaLeF_gtn_p.h5', custom_objects={'GCNConv': GCNConv})\n",
    "\n",
    "ws_pred_gate_true = ws_predictor.predict([test_cov, test_tws_reshape, test_adj_mat])\n",
    "ws_pred_gate_true_inv = ws_scaler.inverse_transform(ws_pred_gate_true)\n",
    "ws_pred_gate_true_inv = ws_pred_gate_true_inv.reshape((-1, 24, 4))\n",
    "ws_pred_gate_true_inv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad36fbd5",
   "metadata": {},
   "source": [
    "### Upper threshould"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "056279a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 96, 96, 118, 117\n",
      "S1, S25A, S25B, S26 areas: 14.82, 15.22, 18, 20.13\n",
      "TOTAL time steps: 427; TOTAL areas: 68.61\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 85, 85, 96, 108\n",
      "S1, S25A, S25B, S26 areas: 11.5466, 12.1773, 13, 17.2181\n",
      "TOTAL time steps: 374; TOTAL areas: 54.3063\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 56, 46, 86, 89\n",
      "S1, S25A, S25B, S26 areas: 5.901, 4.839, 10, 12.3557\n",
      "TOTAL time steps: 277; TOTAL areas: 33.0337\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "upper_threshold = 3.5\n",
    "t1 = 1\n",
    "\n",
    "flood_threshold_t1(ws_true_gate_true_inv, t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_true_inv, t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_pred_inv, t1, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c7bbcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 6, 5, 6, 6\n",
      "S1, S25A, S25B, S26 areas: 0.84, 0.72, 1, 1.0\n",
      "TOTAL time steps: 23; TOTAL areas: 3.62\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 6, 6, 5, 5\n",
      "S1, S25A, S25B, S26 areas: 0.6148, 0.6425, 1, 0.8663\n",
      "TOTAL time steps: 22; TOTAL areas: 3.0018\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 2, 2, 5, 3\n",
      "S1, S25A, S25B, S26 areas: 0.1469, 0.116, 0, 0.2798\n",
      "TOTAL time steps: 12; TOTAL areas: 0.8861\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "flood_threshold_t1(ws_true_gate_true_inv[7640-23:7680-23], t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_true_inv[7640-23:7680-23], t1, upper_threshold)\n",
    "flood_threshold_t1(ws_pred_gate_pred_inv[7640-23:7680-23], t1, upper_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8b3581c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 10248, areas: 1646.6399002075195\n",
      "time steps: 12130, areas: 2088.0380942821503\n",
      "time steps: 12884, areas: 2409.122174024582\n"
     ]
    }
   ],
   "source": [
    "flood_threshold(ws_true_gate_true_inv, upper_threshold)\n",
    "flood_threshold(ws_pred_gate_true_inv, upper_threshold)\n",
    "flood_threshold(ws_pred_gate_pred_inv, upper_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5e11a6",
   "metadata": {},
   "source": [
    "### Lower threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9c7d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 1346, 1341, 1229, 1250\n",
      "S1, S25A, S25B, S26 areas: -385.8, -383.38, -345.08, -350.84:\n",
      "TOTAL time steps: 5166; TOTAL areas: -1465.1\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 1390, 1427, 1282, 1476\n",
      "S1, S25A, S25B, S26 areas: -398.849, -392.0414, -350.2885, -429.5386:\n",
      "TOTAL time steps: 5575; TOTAL areas: -1570.7176\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 479, 83, 45, 204\n",
      "S1, S25A, S25B, S26 areas: -86.2229, -8.5077, -5.0224, -32.8631:\n",
      "TOTAL time steps: 811; TOTAL areas: -132.6161\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "lower_threshold = 0\n",
    "t1 = 1\n",
    "\n",
    "drought_threshold_t1(ws_true_gate_true_inv, t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_true_inv, t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_pred_inv, t1, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d114156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S1, S25A, S25B, S26 time steps: 0, 0, 0, 0\n",
      "S1, S25A, S25B, S26 areas: 0, 0, 0, 0:\n",
      "TOTAL time steps: 0; TOTAL areas: 0\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 0, 0, 0, 0\n",
      "S1, S25A, S25B, S26 areas: 0, 0, 0, 0:\n",
      "TOTAL time steps: 0; TOTAL areas: 0\n",
      "--------------------------------------------------\n",
      "S1, S25A, S25B, S26 time steps: 0, 0, 0, 0\n",
      "S1, S25A, S25B, S26 areas: 0, 0, 0, 0:\n",
      "TOTAL time steps: 0; TOTAL areas: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "drought_threshold_t1(ws_true_gate_true_inv[7640-23:7680-23], t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_true_inv[7640-23:7680-23], t1, lower_threshold)\n",
    "drought_threshold_t1(ws_pred_gate_pred_inv[7640-23:7680-23], t1, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "880f11bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 124148, areas: 35182.6098122485\n",
      "time steps: 127126, areas: 34960.07284716559\n",
      "time steps: 14954, areas: 2426.1538068996733\n"
     ]
    }
   ],
   "source": [
    "drought_threshold(ws_true_gate_true_inv, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_true_inv, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_pred_inv, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2c3007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time steps: 5166, areas: 1465.099992136471\n",
      "time steps: 5575, areas: 1570.7175889443388\n",
      "time steps: 811, areas: 132.61614197987365\n"
     ]
    }
   ],
   "source": [
    "ws_true_gate_true_inv_24 = ws_true_gate_true_inv[:, t1, :]\n",
    "ws_pred_gate_true_inv_24 = ws_pred_gate_true_inv[:, t1, :]\n",
    "ws_pred_gate_pred_inv_24 = ws_pred_gate_pred_inv[:, t1, :]\n",
    "\n",
    "ws_true_gate_true_inv_24 = ws_true_gate_true_inv_24.reshape((-1, 1, 4))\n",
    "ws_pred_gate_true_inv_24 = ws_pred_gate_true_inv_24.reshape((-1, 1, 4))\n",
    "ws_pred_gate_pred_inv_24 = ws_pred_gate_pred_inv_24.reshape((-1, 1, 4))\n",
    "\n",
    "drought_threshold(ws_true_gate_true_inv_24, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_true_inv_24, lower_threshold)\n",
    "drought_threshold(ws_pred_gate_pred_inv_24, lower_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdb658",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16179f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d040d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
